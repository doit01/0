ThingsBoard 中的 ‌AppActor‌ 是整个 Actor 系统的核心调度枢纽，承担租户管理、消息路由和资源协调的关键职责，具体作用如下：

🔧 ‌核心功能‌

租户 Actor 管理中枢‌

作为系统启动时创建的‌唯一顶级常驻 Actor‌，负责动态创建、维护和销毁所有租户（Tenant）对应的 TenantActor 实例 。
每个租户首次接入设备或触发规则时，AppActor 会按需初始化其专属的 TenantActor 。

全局消息路由网关‌

所有外部传入的消息（如设备数据、规则引擎事件）首先由 AppActor 接收，再根据‌租户 ID‌ 精准路由至对应的 TenantActor 邮箱 。
示例：设备上报数据 → AppActor 识别租户 → 转发至目标 TenantActor 。

资源生命周期管控‌

监控租户 Actor 的活动状态，在租户长时间无请求时‌自动回收‌闲置的 TenantActor 以释放内存资源（惰性停止机制）。
确保高并发场景下仅活跃租户占用运行时资源 。
⚙️ ‌协作流程示例‌
mermaid
Copy Code
sequenceDiagram
    participant Device as 设备端
    participant AppActor
    participant TenantActor
    participant RuleChainActor
    
    Device ->> AppActor: 发送数据(含租户ID)
    AppActor ->> TenantActor: 按租户ID路由消息
    TenantActor ->> RuleChainActor: 调用规则链处理
    RuleChainActor -->> Device: 返回响应(如RPC指令)


💡 ‌设计优势‌：

隔离性‌：租户间 Actor 完全独立，故障互不影响 ；
弹性伸缩‌：动态管理租户 Actor，支撑百万级设备接入 ；
简化运维‌：统一入口降低分布式系统复杂度 。


要选择适合实时场景的MQTT QoS等级，需平衡消息可靠性、传输延迟及网络条件，核心决策逻辑如下：

📊 ‌QoS等级特性对比‌
QoS等级‌	传输机制	实时性	可靠性	适用场景案例
QoS 0‌	最多一次（不重传）	⭐⭐⭐⭐	⭐	高频传感器上报（如温度波动）
QoS 1‌	至少一次（自动重传）	⭐⭐⭐	⭐⭐⭐	实时控制指令（如开关灯）
QoS 2‌	恰好一次（四次握手）	⭐	⭐⭐⭐⭐⭐	金融交易、医疗告警
🔍 ‌选择策略‌
1️⃣ ‌优先QoS 0的场景‌
强实时性要求‌：允许少量数据丢失，如高频传感器数据（>10Hz）或实时视频流监控。
网络稳定环境‌：专网或低丢包率场景，避免重传开销。
2️⃣ ‌选择QoS 1的场景‌
需确认送达‌：控制指令（如设备启停）、状态更新（如门锁开关）。
弱网容忍重复‌：接受少量消息重复（客户端需做幂等处理）。
3️⃣ ‌慎用QoS 2的场景‌
严格防重需求‌：支付确认、药品剂量指令等关键操作。
延迟不敏感‌：可接受额外200ms+握手延迟（对比QoS 1）。
⚠️ ‌注意事项‌
服务端降级机制‌
Broker实际按‌发布与订阅端QoS的最低等级‌传输（如Pub端QoS 2 + Sub端QoS 1 → 实际QoS 1）。
客户端性能优化‌
QoS 1/2场景启用异步回调，避免阻塞消息处理线程。
设置合理心跳间隔（如10-30秒），减少假性断连。
网络适应性‌
高抖动网络建议QoS 1而非QoS 2，避免握手失败累积延迟。

💡 ‌决策树示例‌：

mermaid
Copy Code
graph TD
  A[能否容忍消息丢失？] -- 是 --> B[选QoS 0]
  A -- 否 --> C[能否容忍消息重复？]
  C -- 是 --> D[选QoS 1]
  C -- 否 --> E[选QoS 2]

数据流转大概流程

找到MqttTransportService类==》通过@PostConstruct注解在项目启动后进入init()方法
==》里面绑定了MqttTransportServerInitializer类即mqtt服务初始化
==》MqttTransportServerInitializer类继承ChannelInitializer类重写了initChannel方法
==》initChannel方法里绑定了MqttTransportHandler
==》进入MqttTransportHandler的channelRead方法，验证消息类型为mqtt时转入processMqttMsg方法
==》processMqttMsg里进行判断：消息类型为连接时转入processConnect，设备session为临时的转入processProvisionSessionMsg
否则转入enqueueRegularSessionMsg方法，这里先探讨转入enqueueRegularSessionMsg
==》转入enqueueRegularSessionMsg后调用processMsgQueue将消息投递到队列
==》跟进去发现里面调用了processRegularSessionMsg方法
==》processRegularSessionMsg里根据消息的类型进行转发，比如：发布，订阅，取消订阅，取消连接等等
==》跟进PUBLISH，转入processPublish方法
==》转入processDevicePublish，进入发现这里根据消息的主题进行转发，这里选择isDeviceTelemetryTopic对应的transportService.process接口实现
==》发现这里对消息封装了一下之后转入sendToRuleEngine，将消息发送到规则链
》继续跟进进入sendToRuleEngine，发现调用ruleEngineMsgProducer.send，即将消息通过生产者发送到队列
这里对应多个实现，例如：inMemory，Kafka，RabbitMQ等等，默认发送到inMemory内存
》有生产者那肯定有消费者，我们找到DefaultTbRuleEngineConsumerService核心消费者
》找到launchMainConsumers方法》launchConsumer》consumerLoop
》发现consumerLoop是个循环，将消息取出来消费，转submitMessage方法
》然后转入forwardToRuleEngineActor》调用actorContext.tell，这里开始就是Actor模型流转了，不清楚的可以去百度搜索一下
》首先调用appActor.tell通过根appActor调用tell方法转入enqueue方法，里面对消息进行了分类，分为高优先级和正常消息队列
还有initActor()方法创建一系列actor，大概流程：AppActor》TenantActor》RuleChainActor》RuleNodeActor,我们先转入tryProcessQueue方法
==>然后发现调用了processMailbox，发现这里是将之前分类的消息依次取出来然后调用actor.process(msg)方法依次向下流转处理消息

》ContextAwareActor》process==》doProcess==》…
how to make a mqtt server?
0 use netty
1 create MqttTransportService @Service("MqttTransportService")
     @PostConstruct
    public void init() throws Exception {
        log.info("Setting resource leak detector level to {}", leakDetectorLevel);
        ResourceLeakDetector.setLevel(ResourceLeakDetector.Level.valueOf(leakDetectorLevel.toUpperCase()));

        log.info("Starting MQTT transport...");
        bossGroup = new NioEventLoopGroup(bossGroupThreadCount);
        workerGroup = new NioEventLoopGroup(workerGroupThreadCount);
        ServerBootstrap b = new ServerBootstrap();
        b.group(bossGroup, workerGroup)
                .channel(NioServerSocketChannel.class)
                .childHandler(new MqttTransportServerInitializer(context, false))
                .childOption(ChannelOption.SO_KEEPALIVE, keepAlive);

        serverChannel = b.bind(host, port).sync().channel();
        if (sslEnabled) {
            b = new ServerBootstrap();
            b.group(bossGroup, workerGroup)
                    .channel(NioServerSocketChannel.class)
                    .childHandler(new MqttTransportServerInitializer(context, true))
                    .childOption(ChannelOption.SO_KEEPALIVE, keepAlive);
            sslServerChannel = b.bind(sslHost, sslPort).sync().channel();
        }
        log.info("Mqtt transport started!");
    }

application jar depending on transport mqtt service.
       <groupId>org.thingsboard.common.transport</groupId>
    <artifactId>mqtt</artifactId>


    2
    MqttTransportServerInitializer initChannel()
     ChannelPipeline pipeline = ch.pipeline();
       pipeline.addLast("decoder", new MqttDecoder(context.getMaxPayloadSize()));
        pipeline.addLast("encoder", MqttEncoder.INSTANCE);
MqttTransportHandler handler = new MqttTransportHandler(context, sslHandler);

        pipeline.addLast(handler);

3 MqttTransportHandler
 public void channelRead(ChannelHandlerContext ctx, Object msg) {
