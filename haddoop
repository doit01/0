spark tutorail
https://blog.csdn.net/Javachichi/article/details/131871627

存储方案替代 HDFS‌
‌存储类型‌ 	配置方式示例 	适用场景 	引用
‌本地文件系统‌ 	df = spark.read.csv("file:///data/") 	开发测试/小数据 	34
‌Amazon S3‌ 	spark.read.parquet("s3a://bucket/")
需配置 core-site.xml 的 S3 密钥 	云端生产环境 	6
‌数据库直连‌ 	spark.read.jdbc(url, table) 	结构化数据导入

Standalone 集群模式（生产部署）‌

    ‌架构特点‌：使用 Spark 内置资源管理器，无需 YARN/Mesos 57
    ‌部署步骤‌：

    bashCopy Code
    # 主节点启动（假设 IP 为 192.168.1.100）
    $SPARK_HOME/sbin/start-master.sh  # Web UI 端口 8080 :ml-citation{ref="5,7" data="citationList"}

    # 工作节点加入（所有节点执行）
    $SPARK_HOME/sbin/start-worker.sh spark://192.168.1.100:7077 :ml-citation{ref="5" data="citationList"}

    # 提交任务到集群
    spark-submit --master spark://192.168.1.100:7077 \
      $SPARK_HOME/examples/jars/spark-examples_*.jar 100 :ml-citation{ref="7" data=

本地单机模式（开发测试）‌

    ‌适用场景‌：快速验证代码逻辑，无需分布式环境
    ‌安装步骤‌：

    bashCopy Code
    # 下载无需 Hadoop 的 Spark 包（选择 Pre-built without Hadoop 版本）:ml-citation{ref="5,6" data="citationList"}
    wget https://archive.apache.org/dist/spark/spark-3.5.0/spark-3.5.0-bin-without-hadoop.tgz

    # 解压并配置环境变量
    tar -zxvf spark-3.5.0-bin-without-hadoop.tgz -C /opt
    export SPARK_HOME=/opt/spark-3.5.0-bin-without-hadoop
    export PATH=$PATH:$SPARK_HOME/bin

    ‌运行验证‌：

    bashCopy Code
    spark-shell  # 启动 Scala Shell
    > sc.parallelize(1 to 100).sum()



将关系型数据库（如MySQL/Oracle）数据同步到Iceberg的完整技术方案如下，涵盖实时与批量场景：

🔄 一、实时增量同步（CDC模式）
核心工具：‌Flink CDC + Iceberg Sink‌

同步流程‌

sql
Copy Code
-- Flink SQL 配置示例（MySQL → Iceberg）:ml-citation{ref="2,4" data="citationList"}
CREATE TABLE mysql_source (
  id BIGINT PRIMARY KEY,
  name STRING,
  update_time TIMESTAMP(3)
) WITH (
  'connector' = 'mysql-cdc',
  'hostname' = 'localhost',
  'port' = '3306',
  'database-name' = 'test_db',
  'table-name' = 'user_table'
);

CREATE TABLE iceberg_sink (
  id BIGINT,
  name STRING,
  update_time TIMESTAMP(3)
) WITH (
  'connector' = 'iceberg',
  'catalog-name' = 'iceberg_catalog',
  'catalog-type' = 'hive',
  'warehouse' = 's3://iceberg-warehouse'
);

INSERT INTO iceberg_sink SELECT * FROM mysql_source;

优势‌：分钟级延迟，自动捕获INSERT/UPDATE/DELETE事件
事务保障‌：Iceberg V2格式支持ACID，确保Exactly-Once语义

分库分表处理‌

使用正则匹配同步多表（如'table-name' = 'order_*'）
合并写入同一Iceberg表，避免数据分散
⏳ 二、批量全量/增量同步
方案1：‌Spark/Flink 批处理作业‌
python
Copy Code
# Spark 读取MySQL写入Iceberg示例:ml-citation{ref="1,6" data="citationList"}
df = spark.read.format("jdbc") \
  .option("url", "jdbc:mysql://localhost:3306/test_db") \
  .option("dbtable", "user_table") \
  .load()

df.writeTo("iceberg_db.user_table").append()

适用场景‌：历史数据初始化或T+1增量同步
调优关键‌：
并行读取：按主键分片（partitionColumn+numPartitions）
小文件合并：写入后触发Iceberg的rewrite_data_files动作
方案2：‌Dinky数据开发平台‌
可视化配置MySQL源表与Iceberg目标表映射关系
自动生成Flink SQL作业，支持定时调度
⚙️ 三、异构数据库迁移（如Hive→Iceberg）

元数据迁移‌

sql
Copy Code
-- 快照方式迁移（零停机）:ml-citation{ref="3,13" data="citationList"}
CALL iceberg_catalog.system.snapshot('hive_db.orders', 'iceberg_db.orders');

原理‌：复制Hive元数据生成Iceberg表，原始数据文件复用

完全迁移‌

sql
Copy Code
-- 替换原表为Iceberg格式:ml-citation{ref="3,14" data="citationList"}
CALL iceberg_catalog.system.migrate('hive_db.orders');

注意‌：需短暂停写，迁移后原表不可用
🔐 四、关键配置与优化
痛点‌	‌解决方案‌
数据一致性‌	开启Iceberg ACID事务（write.format.default=parquet + V2格式）
Schema变更‌	Iceberg Schema Evolution自动兼容字段增删
写入性能‌	启用Flink Checkpoint（间隔10-30s）+ 并行度调优
存储成本‌	S3/OSS生命周期策略：热数据→标准存储，冷数据→低频/归档存储

典型案例‌：某金融平台通过Flink CDC同步10亿级MySQL数据到Iceberg，查询延迟从小时级降至秒级。

⚠️ 五、注意事项
权限控制‌：
Iceberg集成Apache Ranger/Ranger Iceberg插件实现列级权限
版本兼容‌：
Flink 1.14+ 推荐使用Iceberg 1.0+ API
数据回溯‌：
利用Time Travel查询历史快照（SELECT * FROM table TIMESTAMP AS OF '2025-06-10'）

迁移策略选择：‌实时场景用CDC，存量迁移用批处理+快照机制‌，混合负载需启用流批一体架构。



⚖️ 三、技术选型建议
场景‌	‌推荐方案‌	‌核心优势‌
海量冷数据归档	对象存储 (S3/OSS)	成本低、扩展无限	
实时交互式分析	Lakehouse (Delta Lake)	ACID 事务、秒级响应	
高并发低延迟访问	Ceph / Cassandra	随机 IO 性能优异	
流批一体处理	Kafka + 云存储	增量同步与批量回溯融合	
🔮 四、未来趋势
HDFS 定位转型‌：
逐步退居 ‌离线备份‌ 和 ‌历史数据仓库‌ 角色，不再是实时链路核心。
融合架构成为主流‌：
对象存储 + 计算引擎（Spark/Flink） + 数据湖格式（Iceberg）成为新标准。
边缘计算存储革新‌：
轻量级分布式存储（如 MinIO）适配边缘设备数据采集。

so hdfs 面临淘汰。


根据当前大数据存储技术发展趋势（截至2025年6月），HDFS 虽仍广泛使用于特定场景，但其局限性催生了多种替代方案。以下是综合分析：

🔍 一、HDFS 的现状与核心缺陷
仍存应用场景‌
离线批处理‌：大规模历史数据分析（如日志挖掘）仍依赖 HDFS 的吞吐能力。
与 Hadoop 生态绑定‌：MapReduce、Hive 等工具深度集成，传统企业集群沿用较多。
显著短板制约发展‌
缺陷‌	‌影响‌	来源
低延迟访问能力弱	毫秒级响应需求场景（如实时查询）不适用	
小文件存储效率低	大量小文件导致 NameNode 内存压力，计算性能下降	
缺乏并发写入支持	多用户同时修改同一文件受限	
扩容成本高	依赖廉价硬件但运维复杂度上升	
🚀 二、主流替代方案与技术演进
1. ‌云原生存储（对象存储优先）‌
AWS S3 / Azure Blob Storage‌：
优势：无限扩展性、按需付费、天然高可用，兼容 Hadoop 接口（通过 S3A）。
场景：云上数据湖基座，替代 HDFS 作为底层存储。
2. ‌高性能分布式文件系统‌
Ceph‌：
统一存储架构（块/对象/文件），自动故障转移，适合混合云环境。
性能对比：随机读写速度显著优于 HDFS。
Alluxio‌：
内存加速层：为 HDFS/S3 提供缓存，提升实时分析性能。
3. ‌实时数据处理架构‌
Lakehouse 模式（Delta Lake / Iceberg）‌：
融合数仓与数据湖特性，支持 ACID 事务、实时 Upsert。
替代场景：HDFS + Hive 的传统数仓架构。
流式存储（Apache Pulsar / Kafka）‌：
增量数据实时同步，替代 HDFS 的批量导入模式。
4. ‌NoSQL 与 NewSQL 数据库‌
Cassandra‌：
分布式键值存储，适用于高并发低延迟的 Web 应用场景。
TiDB‌：
HTAP 架构，替代 HDFS + HBase 的实时分析组合。


💡 ‌总结‌：
HDFS 在 ‌超大规模离线批处理‌ 场景仍不可替代，但云原生、实时化、融合架构已成趋势。
选型需综合 ‌数据时效性‌、‌成本‌ 及 ‌生态兼容性‌，避免单一技术绑定。


HDFS Hadoop的分布式文件系统，安装jdk ，安装hadoop安装包，启动即可。
上传文件‌ 
hdfs dfs -put /本地路径/文件 /HDFS目标路径  # :ml-citation{ref="6,9" data="citationList"}
hdfs dfs -copyFromLocal /本地文件 /HDFS路径   # 功能类似，可选参数不同 :ml-citation{ref="9,10" data="citationList"}
查看/管理文件‌ 
hdfs dfs -ls /HDFS路径         # 列出目录内容 :ml-citation{ref="6,9" data="citationList"}
hdfs dfs -cat /HDFS路径/文件    # 查看文件内容 :ml-citation{ref="9,10" data="citationList"}
hdfs dfs -rm -r /HDFS路径       # 递归删除目录 :ml-citation{ref="9,11" data="citationList"}
Java API编程（开发集成）‌
通过FileSystem类实现文件读写、元数据操作等
防止小文件问题‌：调整Flume等工具参数（如hdfs.rollSize=128MB），避免海量小文件占用NameNode内存 1。
‌副本策略‌：默认3副本保障容错，可通过-setrep命令调整副本数
典型使用场景
‌场景类型‌ 	‌说明‌ 	‌关键技术点‌
‌海量数据存储‌ 	PB级日志、传感器数据等非结构化/半结构化数据持久化存储 	分布式扩展性、高吞吐量访问 412
‌批处理计算底座‌ 	为MapReduce、Spark等批处理框架提供底层数据源，支持顺序读取 	数据分块存储（默认128MB）13
‌数据仓库底层存储‌ 	Hive、HBase等依赖HDFS存储原始数据，支持SQL查询与分析 	与计算框架深度集成 14
‌冷数据归档‌ 	替代磁带库存储历史数据，成本低且支持在线访问 	高性价比硬件支持 12

不适用场景
    ‌低延迟读写‌：HDFS优化目标是高吞吐量，实时交互式查询（如MySQL）不适用 812。
    ‌频繁修改文件‌：HDFS设计为"一次写入多次读取"，不支持文件随机修改 68。
    ‌海量小文件‌：大量小文件会耗尽NameNode内存（每个文件约150字节元数据）18
Web UI监控‌
访问http://NameNode_IP:50070 查看集群状态

Sqoop工具导入（‌官方推荐方案‌）  关系型数据库数据 导入
基础全表导入
bashCopy Code
sqoop import \
--connect jdbc:mysql://数据库IP:端口/库名 \
--username 用户名 \
--password 密码 \
--table 源表名 \
--target-dir /hdfs/目标路径 :ml-citation{ref="1,2" data="citationList"}
增量导入（避免全量同步）

Sqoop‌ 	离线批处理同步 	支持HDFS/Hive集成，成熟稳定1
‌Debezium‌ 	实时流式同步 	基于CDC的低延迟，支持多源数据库6
‌DataX‌ 	异构数据源同步 	可视化配置，插件化架构3



